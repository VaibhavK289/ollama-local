# ğŸ—ï¸ Allma Studio Architecture

This document provides a deep dive into the architecture of Allma Studio, explaining the design decisions, component interactions, and data flows.

## Table of Contents

- [System Overview](#system-overview)
- [Backend Architecture](#backend-architecture)
- [Frontend Architecture](#frontend-architecture)
- [Data Flow](#data-flow)
- [Service Layer](#service-layer)
- [Database Design](#database-design)
- [Security Architecture](#security-architecture)

---

## System Overview

Allma Studio follows a **microservices-inspired monolith** architecture, where the application is structured as independent services but deployed as a single unit. This provides the benefits of clean separation while avoiding the complexity of distributed systems.

<div align="center">

![System Architecture](../diagrams/architecture-diagram.jpg)

*High-level system architecture showing component interactions*

</div>

**Key Components:**

| Layer | Technology | Responsibility |
|-------|------------|----------------|
| Frontend | React + Vite | User interface, API communication |
| API Gateway | FastAPI | Request routing, validation, CORS |
| Orchestrator | Python | Service coordination, business logic |
| Services | Python async | Domain-specific operations |
| Vector Store | ChromaDB | Embedding storage and similarity search |
| LLM Runtime | Ollama | Local model inference |

---

## Backend Architecture

### Layer Overview

The backend follows a **layered architecture** with clear separation of concerns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Presentation Layer                â”‚
â”‚         (Routes / API Endpoints)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Orchestration Layer               â”‚
â”‚         (Business Logic Coordinator)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               Service Layer                    â”‚
â”‚     (Domain-Specific Business Logic)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               Data Access Layer                â”‚
â”‚    (Database, Vector Store, External APIs)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Details

#### 1. Presentation Layer (Routes)

Located in `orchestration/routes/`, each route file handles HTTP concerns:

| File | Responsibility |
|------|----------------|
| `chat.py` | Chat message handling, streaming responses |
| `rag.py` | Document ingestion, RAG queries |
| `models.py` | Ollama model management |
| `health.py` | System health checks |

**Pattern:**
```python
router = APIRouter(prefix="/chat", tags=["Chat"])

@router.post("/")
async def send_message(
    request: ChatRequest,
    orchestrator: Orchestrator = Depends(get_orchestrator)
):
    return await orchestrator.handle_chat(request)
```

#### 2. Orchestration Layer

The `Orchestrator` class (`orchestration/orchestrator.py`) is the **central coordinator**:

- Receives requests from routes
- Coordinates between multiple services
- Handles cross-cutting concerns
- Returns unified responses

**Key Methods:**
```python
class Orchestrator:
    async def handle_chat(self, request) -> AsyncGenerator:
        """Coordinate chat with optional RAG"""
        
    async def ingest_document(self, file) -> OrchestrationResult:
        """Coordinate document processing"""
        
    async def search_similar(self, query) -> List[Document]:
        """Coordinate similarity search"""
```

#### 3. Service Layer

Each service handles a specific domain:

| Service | Responsibility |
|---------|----------------|
| `RAGService` | Embeddings, retrieval, reranking |
| `DocumentService` | File parsing, text chunking |
| `VectorStoreService` | ChromaDB operations |
| `ConversationService` | Chat history management |

**Service Pattern:**
```python
class RAGService:
    async def initialize(self):
        """Async initialization"""
        
    async def embed_text(self, text: str) -> List[float]:
        """Generate embeddings via Ollama"""
        
    async def retrieve(self, query: str, k: int = 5) -> List[Document]:
        """Retrieve relevant documents"""
```

---

## Frontend Architecture

### Component Hierarchy

```
App.jsx
â”œâ”€â”€ Layout
â”‚   â”œâ”€â”€ Header
â”‚   â”‚   â”œâ”€â”€ Logo
â”‚   â”‚   â”œâ”€â”€ ModelSelector
â”‚   â”‚   â””â”€â”€ ThemeToggle
â”‚   â”œâ”€â”€ Sidebar
â”‚   â”‚   â”œâ”€â”€ ConversationList
â”‚   â”‚   â””â”€â”€ NewChatButton
â”‚   â””â”€â”€ MainContent
â”‚       â””â”€â”€ ChatInterface
â”‚           â”œâ”€â”€ MessageList
â”‚           â”‚   â”œâ”€â”€ UserMessage
â”‚           â”‚   â””â”€â”€ AssistantMessage
â”‚           â”‚       â””â”€â”€ MarkdownRenderer
â”‚           â”œâ”€â”€ InputArea
â”‚           â”‚   â”œâ”€â”€ TextInput
â”‚           â”‚   â”œâ”€â”€ FileUpload
â”‚           â”‚   â””â”€â”€ SendButton
â”‚           â””â”€â”€ RAGToggle
â””â”€â”€ Modals
    â”œâ”€â”€ SettingsModal
    â””â”€â”€ DocumentModal
```

### State Management

Using React hooks for state management:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    App State (Context)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ currentModel: string                                 â”‚
â”‚  â€¢ theme: 'light' | 'dark'                             â”‚
â”‚  â€¢ isBackendAvailable: boolean                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Custom Hooks (Local State)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  useChat()                                              â”‚
â”‚  â€¢ messages: Message[]                                  â”‚
â”‚  â€¢ isLoading: boolean                                   â”‚
â”‚  â€¢ sendMessage: (text) => void                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  useConversations()                                     â”‚
â”‚  â€¢ conversations: Conversation[]                        â”‚
â”‚  â€¢ activeId: string                                    â”‚
â”‚  â€¢ selectConversation: (id) => void                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  useModels()                                            â”‚
â”‚  â€¢ models: Model[]                                      â”‚
â”‚  â€¢ currentModel: string                                â”‚
â”‚  â€¢ switchModel: (name) => void                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### API Service Layer

```
src/services/
â”œâ”€â”€ api.js          # Main API client with demo fallback
â””â”€â”€ demoApi.js      # Simulated responses for demo mode
```

**Auto-Fallback Pattern:**
```javascript
// api.js
let isBackendAvailable = null;

export async function checkBackendAvailable() {
  try {
    await axios.get(`${API_URL}/health`, { timeout: 3000 });
    isBackendAvailable = true;
  } catch {
    isBackendAvailable = false;
  }
  return isBackendAvailable;
}

export async function sendMessage(message, useRag) {
  if (!isBackendAvailable) {
    return demoApi.sendMessage(message, useRag);
  }
  return axios.post(`${API_URL}/chat/`, { message, use_rag: useRag });
}
```

---

## Data Flow

### RAG Implementation Architecture

<div align="center">

![RAG Implementation Architecture](../diagrams/RAG_Implementation_Architecture_Diagram.jpg)

*Complete RAG pipeline showing query processing through response generation*

</div>

The RAG pipeline follows this flow:

1. **Query Input**: User submits a question
2. **Embedding**: Query converted to vector via Nomic Embed Text
3. **Similarity Search**: ChromaDB finds relevant document chunks
4. **Context Assembly**: Top-k results assembled into context
5. **Prompt Augmentation**: Context injected into LLM prompt
6. **Generation**: Ollama generates response with sources

### Document Ingestion Pipeline

<div align="center">

![RAG Ingestion Pipeline](../diagrams/RAG_ingestion_Diagram.png)

*Document processing from upload to vector storage*

</div>

**Ingestion Stages:**

| Stage | Component | Description |
|-------|-----------|-------------|
| Load | DocumentService | Parse PDF, DOCX, MD, TXT, HTML, JSON, CSV |
| Extract | TextSplitter | Extract text with metadata preservation |
| Chunk | TextSplitter | Split into overlapping chunks (default: 1000 chars, 200 overlap) |
| Embed | RAGService | Generate embeddings via Ollama API |
| Store | VectorStoreService | Persist to ChromaDB with metadata |

### Entity Relationships

<div align="center">

![Entity Relationship Diagram](../diagrams/Entity_Relationship_Diagram.png)

*Data model showing relationships between entities*

</div>

**Key Relationships:**
- **Document** (1) â†’ (N) **Chunks**: Documents split for embedding
- **Chunk** (1) â†’ (1) **Embedding**: Each chunk has one vector
- **Conversation** (1) â†’ (N) **Messages**: Chat history
- **Message** (N) â†’ (N) **Sources**: RAG source references

---

## Service Layer

### RAGService

Handles all RAG-related operations:

```python
class RAGService:
    """
    Retrieval-Augmented Generation Service
    
    Responsibilities:
    - Generate embeddings via Ollama
    - Retrieve relevant documents
    - Rerank results for relevance
    - Build context for LLM
    """
    
    async def embed_text(self, text: str) -> List[float]:
        """Generate embedding vector for text"""
        response = await self.ollama_client.post("/api/embeddings", {
            "model": self.embedding_model,
            "prompt": text
        })
        return response["embedding"]
    
    async def retrieve(self, query: str, k: int = 5) -> List[Document]:
        """Retrieve k most similar documents"""
        query_embedding = await self.embed_text(query)
        return await self.vector_store.similarity_search(query_embedding, k)
    
    def build_context(self, documents: List[Document]) -> str:
        """Format documents into LLM context"""
        return "\n\n".join([
            f"[Source: {doc.metadata.get('source', 'unknown')}]\n{doc.content}"
            for doc in documents
        ])
```

### DocumentService

Handles document processing:

```python
class DocumentService:
    """
    Document Processing Service
    
    Responsibilities:
    - Parse various file formats
    - Split documents into chunks
    - Extract metadata
    """
    
    SUPPORTED_FORMATS = ['.txt', '.md', '.pdf', '.docx']
    
    async def parse_document(self, file: UploadFile) -> str:
        """Extract text from uploaded file"""
        
    def chunk_text(self, text: str, chunk_size: int = 500) -> List[Chunk]:
        """Split text into overlapping chunks"""
        
    def extract_metadata(self, file: UploadFile) -> Dict:
        """Extract file metadata"""
```

### VectorStoreService

Manages ChromaDB operations:

```python
class VectorStoreService:
    """
    Vector Store Service (ChromaDB)
    
    Responsibilities:
    - Initialize and manage ChromaDB client
    - Store document embeddings
    - Perform similarity searches
    - Handle persistence
    """
    
    async def add_documents(self, documents: List[Document]) -> None:
        """Store documents with embeddings"""
        
    async def similarity_search(
        self, 
        embedding: List[float], 
        k: int = 5
    ) -> List[Document]:
        """Find k most similar documents"""
        
    async def delete_collection(self, collection_name: str) -> None:
        """Remove a document collection"""
```

---

## Database Design

### SQLite (Conversation Storage)

```sql
-- Conversations Table
CREATE TABLE conversations (
    id TEXT PRIMARY KEY,
    title TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Messages Table
CREATE TABLE messages (
    id TEXT PRIMARY KEY,
    conversation_id TEXT NOT NULL,
    role TEXT NOT NULL,  -- 'user' | 'assistant'
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES conversations(id)
);

-- RAG Sources Table (for message context)
CREATE TABLE message_sources (
    id TEXT PRIMARY KEY,
    message_id TEXT NOT NULL,
    document_id TEXT NOT NULL,
    chunk_id TEXT NOT NULL,
    relevance_score REAL,
    FOREIGN KEY (message_id) REFERENCES messages(id)
);
```

### ChromaDB (Vector Storage)

```
Collection: documents
â”œâ”€â”€ Embeddings: float[768]  (nomic-embed-text dimensions)
â”œâ”€â”€ Documents: string       (chunk content)
â””â”€â”€ Metadata:
    â”œâ”€â”€ source: string      (filename)
    â”œâ”€â”€ chunk_index: int    (position in document)
    â”œâ”€â”€ created_at: string  (timestamp)
    â””â”€â”€ doc_id: string      (parent document ID)
```

---

## Security Architecture

### API Security

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Security Layers                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. CORS Policy                                         â”‚
â”‚     â€¢ Configurable allowed origins                      â”‚
â”‚     â€¢ Preflight request handling                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. Rate Limiting                                       â”‚
â”‚     â€¢ Per-IP request limits                            â”‚
â”‚     â€¢ Configurable thresholds                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. Input Validation                                    â”‚
â”‚     â€¢ Pydantic model validation                        â”‚
â”‚     â€¢ File type restrictions                           â”‚
â”‚     â€¢ Size limits                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. Error Handling                                      â”‚
â”‚     â€¢ Sanitized error messages                         â”‚
â”‚     â€¢ No stack traces in production                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Container Security

```dockerfile
# Non-root user
RUN addgroup --system --gid 1001 appgroup && \
    adduser --system --uid 1001 appuser
USER appuser

# Read-only filesystem
--read-only

# No new privileges
--security-opt=no-new-privileges:true

# Resource limits
--memory=2g
--cpus=1
```

### Data Privacy

- **Zero Telemetry**: No data collection or phone-home
- **Local Processing**: All LLM inference happens locally
- **User Data Control**: Data stored locally, easily deletable
- **No Cloud Dependencies**: Works fully offline

---

## Performance Considerations

### Caching Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Caching Layers                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L1: In-Memory Cache                                    â”‚
â”‚      â€¢ Embedding cache (LRU, 1000 items)               â”‚
â”‚      â€¢ Model info cache (TTL: 5 minutes)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L2: ChromaDB Cache                                     â”‚
â”‚      â€¢ Persisted vectors                               â”‚
â”‚      â€¢ SQLite-backed                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L3: Response Cache (Future)                            â”‚
â”‚      â€¢ Repeated query caching                          â”‚
â”‚      â€¢ Configurable TTL                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Async Operations

All I/O operations are async for maximum concurrency:

```python
# Parallel embedding generation
embeddings = await asyncio.gather(*[
    self.embed_text(chunk) for chunk in chunks
])

# Parallel file operations
results = await asyncio.gather(
    self.save_to_db(document),
    self.store_vectors(embeddings),
    self.update_metadata(doc_id)
)
```

---

## Extension Points

### Adding New LLM Providers

1. Create new service in `services/`:
```python
class CloudLLMService:
    async def generate(self, prompt: str) -> AsyncGenerator[str, None]:
        """Stream response from cloud provider"""
```

2. Register in Orchestrator
3. Add configuration to `config.py`

### Adding New Document Types

1. Add parser to `DocumentService`:
```python
def parse_xlsx(self, file: UploadFile) -> str:
    """Parse Excel files"""
```

2. Update `SUPPORTED_FORMATS`
3. Add handling in route

### Adding New Vector Stores

1. Implement `VectorStoreBackend` ABC:
```python
class FaissBackend(VectorStoreBackend):
    async def add(self, embeddings, documents): ...
    async def search(self, embedding, k): ...
```

2. Configure in `config.py`
